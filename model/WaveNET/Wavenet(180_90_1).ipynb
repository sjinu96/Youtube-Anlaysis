{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T03:17:33.191705Z",
     "start_time": "2020-11-20T03:17:33.186707Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, date\n",
    "from sklearn import utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def _fit_transform(self, raw):\n",
    "        result = raw.copy()\n",
    "\n",
    "        result = self._n_comment_to_float(result)\n",
    "        result = self._str_to_datetype(result)\n",
    "        result = self._add_n_hashtag(result)\n",
    "        \n",
    "        self.non_numeric = ['channel', 'title', 'genre', 'description', 'date', 'sign_in']\n",
    "        result = self._merge(result, self.non_numeric)\n",
    "        \n",
    "        features = ['cumul_view', 'n_dislike', 'n_like', 'n_comment', 'video_n_view', 'cumul_subs']\n",
    "        new_name = ['view_diff', 'dislike_diff', 'like_diff', 'comment_diff', 'video_n_view_diff', 'sub_diff']\n",
    "        result = self._add_diff(result, features, new_name)\n",
    "        \n",
    "        result = self._add_no_upload_interval(result)\n",
    "        result = self._remove_nan(result)\n",
    "        self._one_hot(result)\n",
    "\n",
    "        return result\n",
    "        \n",
    "        \n",
    "        \n",
    "    #FEATRUES TO ADD & MODIFY\n",
    "    ####################################################################     \n",
    "    def _n_comment_to_float(self,result):\n",
    "        idx1 = result['n_comment'] == '댓글 사용 중지'\n",
    "        idx2 = result.n_comment.isna()\n",
    "        idx = idx1|idx2\n",
    "        result['n_comment'].loc[idx] = result['n_comment'].loc[idx].apply(lambda x: 0)\n",
    "        result['n_comment'] = result['n_comment'].astype(float)\n",
    "        return result\n",
    "        \n",
    "    \n",
    "    def _str_to_datetype(self,result):\n",
    "        if pd.api.types.is_datetime64_ns_dtype(result['date']):\n",
    "            pass\n",
    "        else:\n",
    "            result['date'] = pd.to_datetime(result['date'])\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def _add_n_hashtag(self,result):\n",
    "        result['n_hashtage'] = 0\n",
    "        idx = result['description'].notnull()\n",
    "        result.loc[idx, 'n_hashtage'] = result.loc[idx, 'description'].apply(lambda x: len(x.split('#'))-1)\n",
    "        return result\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_to_merge(data, numeric, non_numeric):\n",
    "        data = data.reset_index(drop=True)\n",
    "        num_to_add = data.title.shape[0] - data.title.isna().sum()\n",
    "        data = pd.concat((data.loc[0,non_numeric], data[numeric].mean()))\n",
    "        data['video_num'] = num_to_add\n",
    "        return data\n",
    "    def _merge(self, result, non_numeric):\n",
    "        #operate both merge and creating video_num featrue simultaneously.\n",
    "        numeric = [col for col in result.columns.tolist() if col not in non_numeric]\n",
    "        return result.groupby(['channel', 'date']).apply(lambda x: self._get_to_merge(x, numeric, non_numeric)).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_diff(result, feature, new_name):\n",
    "        result = result.reset_index(drop=True)\n",
    "        result[new_name] = (result[feature] - result[feature].shift())\n",
    "        return result\n",
    "    def _add_diff(self, result, feature, new_name):\n",
    "        result = result.groupby('channel').apply(lambda x: self._get_diff(x, feature, new_name)).reset_index(drop=True)\n",
    "        result[new_name] = result[new_name].fillna(0)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_no_upload_interval(result):\n",
    "        result = result.reset_index(drop=True)\n",
    "        upload_idx = result[result['video_num'] != 0].index.tolist()\n",
    "        temp = [0 for i in range(result.shape[0])]\n",
    "        for i in range(len(upload_idx)):\n",
    "            if i == len(upload_idx)-1:\n",
    "                former = upload_idx[i]\n",
    "                temp[former+1:] = [i+1 for i in range(len(temp[former+1:]))]\n",
    "            else:\n",
    "                former, latter = upload_idx[i], upload_idx[i+1]\n",
    "                temp[former+1:latter] = [i+1 for i in range(len(temp[former+1:latter]))]\n",
    "        result['no_upload_interval'] = temp\n",
    "        return result\n",
    "    def _add_no_upload_interval(self,result):\n",
    "        return result.groupby('channel').apply(lambda x: self._get_no_upload_interval(x)).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    def _remove_nan(self, result):\n",
    "        numeric = [col for col in result.columns.tolist() if col not in self.non_numeric]\n",
    "        result.loc[:, numeric] = result.loc[:,numeric].fillna(0)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def _one_hot(self, data):\n",
    "        data.loc[:,'genre'] = data.genre.fillna('etc')\n",
    "        genre = data.genre.unique().tolist()\n",
    "        for i, name in enumerate(genre):\n",
    "            data.genre[data.genre==name] = data.genre[data.genre==name].apply(lambda x: i)\n",
    "            \n",
    "        one_hot = pd.get_dummies(data.genre.unique().tolist())\n",
    "        data['one_hot'] = data.genre\n",
    "        for i in range(len(one_hot)):\n",
    "            data.loc[data.genre==i,'one_hot'] = data.loc[data.genre==i, 'genre'].apply(lambda x: one_hot[i].values)\n",
    "    ####################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    #CREATE SEQUENTIAL DATA\n",
    "    ####################################################################\n",
    "    def _extract_at_least_filter(self, result, filter_size):\n",
    "        #fillter_size 이상인 채널 추출하기\n",
    "        alive_idx = result['channel'].value_counts() >= filter_size\n",
    "        alive_array = alive_idx[alive_idx==True].index\n",
    "        return result[result['channel'].isin(alive_array)].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _to_sequential(result, filter_size, target_size, stride, features, target_features):\n",
    "        result = result.reset_index(drop=True)\n",
    "        idx_list = result.index.tolist()\n",
    "        \n",
    "        train, target = [],[]\n",
    "        for i in range((len(idx_list)-filter_size-target_size)//stride +1):\n",
    "            train_idx = idx_list[i*stride : i*stride + filter_size]\n",
    "            target_idx = idx_list[i*stride + filter_size : i*stride + filter_size + target_size]\n",
    "            train_temp = result.loc[train_idx,:].values.reshape(1,-1)\n",
    "            target_temp = result.loc[target_idx,target_features].values.reshape(1,-1)\n",
    "            \n",
    "            train = train_temp.copy() if i == 0 else np.vstack([train, train_temp])\n",
    "            target = target_temp.copy() if i == 0 else np.vstack([target, target_temp])\n",
    "            \n",
    "        train = pd.DataFrame(train, columns = result.columns.tolist()*filter_size)\n",
    "        target = pd.DataFrame(target, columns = target_features*target_size)\n",
    "        return train[features], target\n",
    "    def _create_sequential_data(self, result, filter_size=7, target_size=1, stride=1, features=None, target_features=None):\n",
    "        #remove channels with few information with respect to filter_size and target_size to extract\n",
    "        result = self._extract_at_least_filter(result, filter_size + target_size)\n",
    "        \n",
    "        #features: features to drop fromf X (features)\n",
    "        #target_features: features to extract from Y (targets)\n",
    "        if features is None:\n",
    "            features = ['date', 'genre','title', 'channel', 'description',\t'sign_in', 'current_cumul_view', 'current_n_video', 'current_cumul_subs']\n",
    "        if target_features is None:\n",
    "            target_features = ['sub_diff']\n",
    "        \n",
    "        #return train, target set wrt groups\n",
    "        result = result.groupby('channel').apply(lambda x: self._to_sequential(x, filter_size, target_size, stride, features, target_features)).reset_index(drop=True)\n",
    "        return self._combine(result)\n",
    "    \n",
    "    \n",
    "    def _combine(self, result):\n",
    "        temp0, temp1 = [], []\n",
    "        for i in range(len(result)):\n",
    "            temp0.append(result[i][0])\n",
    "            temp1.append(result[i][1])\n",
    "        temp0 = pd.concat(temp0)\n",
    "        temp1 = pd.concat(temp1)\n",
    "        return (temp0, temp1)\n",
    "    ####################################################################\n",
    "\n",
    "\n",
    "    \n",
    "    #SCALE\n",
    "    ####################################################################\n",
    "    def scale(self, data, return_original_scale=True):\n",
    "        original_scale = pd.concat((data.max(), data.min()), axis=1).T\n",
    "        original_scale.index=['max', 'min']\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "        if return_original_scale:\n",
    "            return data, original_scale\n",
    "        return data\n",
    "    \n",
    "        \n",
    "    def inverse_scale(self, pred, scl):\n",
    "        for idx in range(pred.shape[1]):\n",
    "            pred.iloc[:,idx] = (scl.iloc[0,idx]-scl.iloc[1,idx])*pred.iloc[:,idx]+scl.iloc[1,idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader(Preprocessor):\n",
    "    def __init__(self, path):\n",
    "        self._raw = pd.read_csv(path)\n",
    "        self.data = super()._fit_transform(self._raw.copy())\n",
    "        print('Data Loaded. :P')\n",
    "        \n",
    "        \n",
    "    def get_data(self, filter_size=7, target_size=1, stride=1, features=None, target_features=None,\n",
    "                         channel:list=None, shuffle=False, random_state=None, order=None):\n",
    "        if channel is None:\n",
    "            data_to_extract = self.data\n",
    "        else:\n",
    "            channels = self.list_channel[channel].tolist()\n",
    "            data_to_extract = self.data.set_index('channel').loc[channels].reset_index()\n",
    "            \n",
    "        train, target = self._create_sequential_data(data_to_extract, filter_size, target_size, stride, features, target_features)\n",
    "        if shuffle:\n",
    "            train, target = utils.shuffle(train, target, random_state=random_state)\n",
    "        \n",
    "        if order:\n",
    "            train_col = [col for col in train.columns.unique().tolist()]\n",
    "            target_col = [col for col in target.columns.unique().tolist()]\n",
    "            train, target = train[train_col], target[target_col]\n",
    "            \n",
    "        return train, target\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def list_features(self):\n",
    "        #list the entire features, hence you can choose which features are included in whole set.\n",
    "        return self.data.columns.tolist()\n",
    "    \n",
    "    @property\n",
    "    def list_channel(self):\n",
    "        #list indices of channel.\n",
    "        return pd.Series(self.data.channel.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> load함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(\n",
    "    filter_size: '60, 90, 180', \n",
    "    target_size: '1, 7, 30, 180', \n",
    "    stride: '1, 2, 3',\n",
    "    drop_suffix: '각 변수 끝에 붙은 번호를 제거할지 여부'=True,\n",
    "    path='/home/mskang/CapstoneUOS/notebooks/ModelResearch_iloveslowfood/data_variants'):\n",
    "    \n",
    "    print(f'Setting: filter_size({filter_size})\\ttarget_size({target_size})\\tstride({stride})\\tdrop_suffix({drop_suffix})')\n",
    "    X_name = f'fs({filter_size})_ts({target_size})_st({stride}).csv'\n",
    "    y_name = f'fs({filter_size})_ts({target_size})_st({stride})_label.csv'\n",
    "    \n",
    "    print('Load feature data...', end='\\t')\n",
    "    X = pd.read_csv(os.path.join(path, X_name))\n",
    "    print('loaded!')\n",
    "    print('Load label data...', end='\\t')\n",
    "    y = pd.read_csv(os.path.join(path, y_name))\n",
    "    print('loaded!')\n",
    "    \n",
    "    if drop_suffix:\n",
    "        X.columns = list(map(lambda x: x.split('.')[0], X.columns.tolist()))\n",
    "        y.columns = list(map(lambda x: x.split('.')[0], y.columns.tolist()))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting: filter_size(180)\ttarget_size(90)\tstride(1)\tdrop_suffix(True)\n",
      "Load feature data...\tloaded!\n",
      "Load label data...\tloaded!\n"
     ]
    }
   ],
   "source": [
    "filter_size = 180\n",
    "target_size = 90\n",
    "stride = 1\n",
    "X, y = load(filter_size, target_size, stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Train/Test/VAlid 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "test_size = 0.2\n",
    "\n",
    "X_trn, X_test, y_trn, y_test = train_test_split(\n",
    "    X, y, \n",
    "    shuffle=True, \n",
    "    test_size=test_size, \n",
    "    random_state=random_state\n",
    ") \n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_trn, y_trn, \n",
    "    shuffle=True, \n",
    "    test_size=test_size, \n",
    "    random_state=random_state\n",
    ") \n",
    "\n",
    "### 스케일링 필요 시 다음을 진행(타깃에 대한 스케일링은 진행되지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "# X_valid_scaled = pd.DataFrame(scaler.transform(X_valid), columns=X_valid.columns)\n",
    "# X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D TO 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_to_multi(df):\n",
    "    feature_num=len(set(df.columns))\n",
    "    window_num=int(df.shape[1]/feature_num)\n",
    "    sample_num=int(df.shape[0])\n",
    "    temp=np.empty([sample_num,window_num,feature_num])\n",
    "    for i in range(feature_num):\n",
    "        temp[:,:,i]=df.iloc[:,window_num*i:window_num*i+window_num]\n",
    "    \n",
    "    return temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>...</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22536</th>\n",
       "      <td>12.350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.016667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32069</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38047</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.350</td>\n",
       "      <td>97.98</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>12.885</td>\n",
       "      <td>11.5</td>\n",
       "      <td>6.275</td>\n",
       "      <td>7.67</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36987</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>110</td>\n",
       "      <td>111</td>\n",
       "      <td>112</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8980</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36503</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26876 rows × 3060 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration  duration  duration  duration  duration  duration  duration  \\\n",
       "22536    12.350       0.0     0.000      0.00  7.016667      0.00      0.00   \n",
       "32069     0.000       0.0     0.000      0.00  0.000000      0.00      0.00   \n",
       "38047     0.000       0.0     0.000      0.00  0.000000      0.00      0.00   \n",
       "11608     0.000       0.0    28.350     97.98  0.000000      0.00     43.13   \n",
       "1338      0.000       0.0     0.000      0.00  0.000000      0.00      0.00   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "6301     12.885      11.5     6.275      7.67  0.000000      0.00      3.05   \n",
       "36987     0.000       0.0     0.000      0.00  0.000000      0.00      0.00   \n",
       "10958     0.000       0.0     0.000      0.00  0.000000      0.00      0.00   \n",
       "8980      0.000       0.0     0.000      0.00  3.580000      0.00      0.00   \n",
       "36503     0.000       0.0     0.000      0.00  0.000000     17.77      0.00   \n",
       "\n",
       "       duration  duration  duration  ...  no_upload_interval  \\\n",
       "22536       0.0       0.0      0.00  ...                  13   \n",
       "32069       0.0       0.0      0.00  ...                  92   \n",
       "38047       0.0       0.0      0.00  ...                   0   \n",
       "11608       0.0       0.0     27.88  ...                   0   \n",
       "1338        0.0       0.0      0.00  ...                   5   \n",
       "...         ...       ...       ...  ...                 ...   \n",
       "6301        0.0       7.8      8.25  ...                   0   \n",
       "36987       0.0       0.0      0.00  ...                   0   \n",
       "10958       0.0       0.0      0.00  ...                 104   \n",
       "8980        0.0       0.0      0.00  ...                  10   \n",
       "36503       0.0       0.0      0.00  ...                   0   \n",
       "\n",
       "       no_upload_interval  no_upload_interval  no_upload_interval  \\\n",
       "22536                   0                   1                   2   \n",
       "32069                  93                  94                  95   \n",
       "38047                   0                   0                   0   \n",
       "11608                   1                   2                   3   \n",
       "1338                    6                   7                   8   \n",
       "...                   ...                 ...                 ...   \n",
       "6301                    1                   0                   1   \n",
       "36987                   1                   0                   0   \n",
       "10958                 105                 106                 107   \n",
       "8980                   11                  12                  13   \n",
       "36503                   1                   2                   3   \n",
       "\n",
       "       no_upload_interval  no_upload_interval  no_upload_interval  \\\n",
       "22536                   3                   4                   5   \n",
       "32069                  96                  97                  98   \n",
       "38047                   0                   0                   0   \n",
       "11608                   4                   5                   6   \n",
       "1338                    9                  10                  11   \n",
       "...                   ...                 ...                 ...   \n",
       "6301                    2                   3                   0   \n",
       "36987                   0                   1                   0   \n",
       "10958                 108                 109                 110   \n",
       "8980                   14                  15                  16   \n",
       "36503                   4                   5                   6   \n",
       "\n",
       "       no_upload_interval  no_upload_interval  no_upload_interval  \n",
       "22536                   6                   7                   8  \n",
       "32069                  99                 100                 101  \n",
       "38047                   0                   0                   0  \n",
       "11608                   0                   0                   1  \n",
       "1338                   12                  13                   0  \n",
       "...                   ...                 ...                 ...  \n",
       "6301                    0                   1                   2  \n",
       "36987                   0                   0                   0  \n",
       "10958                 111                 112                 113  \n",
       "8980                   17                  18                  19  \n",
       "36503                   0                   1                   2  \n",
       "\n",
       "[26876 rows x 3060 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3d=stack_to_multi(X_train)\n",
    "X_valid_3d=stack_to_multi(X_valid)\n",
    "X_test_3d=stack_to_multi(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26876, 180, 17)\n",
      "(6720, 180, 17)\n",
      "(8399, 180, 17)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_3d.shape)\n",
    "print(X_valid_3d.shape)\n",
    "print(X_test_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26876, 90)\n",
      "(6720, 90)\n",
      "(8399, 90)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D 스케일링, 타겟 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=preprocessing.MinMaxScaler()\n",
    "#scaler_y=preprocessing.MinMaxScaler()\n",
    "def fit_3d(x_train,x_val,x_test):\n",
    "    x_train_sample = x_train.shape[0] #샘플 개수\n",
    "    x_val_sample=x_val.shape[0]\n",
    "    x_test_sample=x_test.shape[0]\n",
    "    \n",
    "    x_timestep = x_train.shape[1] # timestep\n",
    "    x_feature = x_train.shape[2]# feature 차원 \n",
    "    scaler=MinMaxScaler()\n",
    "    for ss in range(x_timestep):\n",
    "        scaler.partial_fit(x_train[:, ss, :]) # 순회피팅\n",
    "\n",
    "    results1,results2,results3=([],[],[])\n",
    "    for ss in range(x_timestep):\n",
    "        results1.append(scaler.transform(x_train[:, ss, :]).reshape(x_train_sample, 1, x_feature))\n",
    "        results2.append(scaler.transform(x_val[:,ss,:]).reshape(x_val_sample,1,x_feature))\n",
    "        results3.append(scaler.transform(x_test[:,ss,:]).reshape(x_test_sample,1,x_feature))\n",
    "    df_train_scaled = np.concatenate(results1, axis=1) #합치기.\n",
    "    df_val_scaled=np.concatenate(results2,axis=1)\n",
    "    df_test_scaled=np.concatenate(results3,axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df_train_scaled,df_val_scaled,df_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled,X_valid_scaled,X_test_scaled=fit_3d(X_train_3d, X_valid_3d, X_test_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> target shape 변경 ( 샘플 x 타입스텝 x 예측일수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subdiff=X_train['sub_diff']\n",
    "X_valid_subdiff=X_valid['sub_diff']\n",
    "X_test_subdiff=X_test['sub_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22536</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32069</th>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38047</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36987</th>\n",
       "      <td>399.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>700.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8980</th>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36503</th>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26876 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sub_diff  sub_diff  sub_diff  sub_diff  sub_diff  sub_diff  sub_diff  \\\n",
       "22536       0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "32069       0.0      99.0     100.0       0.0       0.0       0.0     100.0   \n",
       "38047       3.0      -1.0       2.0       2.0       4.0       0.0      -1.0   \n",
       "11608      10.0       0.0      10.0      10.0      10.0      10.0      20.0   \n",
       "1338        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "6301        1.0       3.0       2.0       0.0       0.0       0.0       1.0   \n",
       "36987     399.0     501.0     500.0     500.0     500.0     499.0     501.0   \n",
       "10958      23.0      22.0      22.0      22.0      22.0      22.0      22.0   \n",
       "8980        0.0     101.0      99.0     101.0      50.0      50.0     100.0   \n",
       "36503     500.0    1000.0    1000.0     500.0     500.0       0.0       0.0   \n",
       "\n",
       "       sub_diff  sub_diff  sub_diff  ...  sub_diff  sub_diff  sub_diff  \\\n",
       "22536       0.0       5.0       6.0  ...       1.0       0.0       0.0   \n",
       "32069     100.0       0.0       0.0  ...       0.0     100.0     100.0   \n",
       "38047       2.0       1.0       0.0  ...       1.0       0.0       1.0   \n",
       "11608       5.0      -5.0      10.0  ...      20.0      30.0      60.0   \n",
       "1338        0.0       0.0       0.0  ...     100.0     100.0       0.0   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "6301        1.0       1.0       1.0  ...     100.0     100.0     100.0   \n",
       "36987     500.0     500.0     500.0  ...     700.0     500.0     600.0   \n",
       "10958      18.0      19.0      14.0  ...       0.0       0.0       0.0   \n",
       "8980        0.0     100.0     100.0  ...       0.0       0.0      99.0   \n",
       "36503    3000.0    1300.0    1300.0  ...    1000.0    1000.0     500.0   \n",
       "\n",
       "       sub_diff  sub_diff  sub_diff  sub_diff  sub_diff  sub_diff  sub_diff  \n",
       "22536       1.0       0.0       1.0       0.0       1.0       1.0       0.0  \n",
       "32069       0.0     100.0     100.0       0.0     100.0     100.0     100.0  \n",
       "38047       0.0       1.0      -1.0       0.0       0.0       0.0       0.0  \n",
       "11608      20.0      20.0      20.0      10.0      30.0      25.0      25.0  \n",
       "1338        0.0     100.0       0.0     100.0     100.0       0.0     100.0  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "6301      100.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "36987    1100.0     200.0     700.0     500.0     500.0     500.0     500.0  \n",
       "10958       0.0      50.0      50.0       0.0       0.0     100.0       0.0  \n",
       "8980        0.0     101.0       0.0     200.0       0.0      99.0     101.0  \n",
       "36503     500.0    2000.0    1000.0       0.0    1000.0       0.0    1000.0  \n",
       "\n",
       "[26876 rows x 180 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_subdiff[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (샘플개수 , (180+30)의 TARGET\n",
    "temp1=pd.concat([X_train_subdiff,y_train],axis=1)\n",
    "temp2=pd.concat([X_valid_subdiff,y_valid],axis=1)\n",
    "temp3=pd.concat([X_test_subdiff,y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (샘플, timestep, targetsize)\n",
    "y_train_3d=np.empty((X_train_subdiff.shape[0],X_train_subdiff.shape[1],90)) # 30 : targetsize\n",
    "y_valid_3d=np.empty((X_valid_subdiff.shape[0],X_valid_subdiff.shape[1],90))\n",
    "y_test_3d=np.empty((X_test_subdiff.shape[0],X_test_subdiff.shape[1],90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(X_train_subdiff.shape[1]): # 180 Timestep\n",
    "    y_train_3d[:,t]=temp1.iloc[:,t:t+90]\n",
    "    y_valid_3d[:,t]=temp2.iloc[:,t:t+90]\n",
    "    y_test_3d[:,t]=temp3.iloc[:,t:t+90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26876, 180, 90)\n",
      "(6720, 180, 90)\n",
      "(8399, 180, 90)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_3d.shape)\n",
    "print(y_valid_3d.shape)\n",
    "print(y_test_3d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> y scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_temp=y_train_3d.reshape(-1,1)\n",
    "y_valid_temp=y_valid_3d.reshape(-1,1)\n",
    "y_test_temp=y_test_3d.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_y=MinMaxScaler()\n",
    "y_train_scaled=scaler_y.fit_transform(y_train_temp)\n",
    "y_val_scaled=scaler_y.transform(y_valid_temp)\n",
    "y_test_scaled=scaler_y.transform(y_test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scaled=y_train_scaled.reshape(y_train_3d.shape[0],y_train_3d.shape[1],y_train_3d.shape[2])\n",
    "y_valid_scaled=y_val_scaled.reshape(y_valid_3d.shape[0],y_valid_3d.shape[1],y_valid_3d.shape[2])\n",
    "y_test_scaled=y_test_scaled.reshape(y_test_3d.shape[0],y_test_3d.shape[1],y_test_3d.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26876, 180, 90)\n",
      "(6720, 180, 90)\n",
      "(8399, 180, 90)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_scaled.shape)\n",
    "print(y_valid_scaled.shape)\n",
    "print(y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 마지막 Timestep의 loss만 중요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_absolute_error(Y_true[:, -1], Y_pred[:, -1]) #### <<- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "    filename='Wavenet(180_90_1)(filtersize:180).h5'\n",
    "callback_list1 = [tf.keras.callbacks.ModelCheckpoint(filepath='Checkpoint/{}'.format(filename),\n",
    "                                                    monitor='val_last_time_step_mse',\n",
    "                                                    verbose=1,\n",
    "                                                    save_best_only=True,\n",
    "                                                    mode='min'),\n",
    "                 tf.keras.callbacks.EarlyStopping(monitor='val_last_time_step_mse',\n",
    "                                                  patience=15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Full=keras.models.Sequential()\n",
    "model_Full.add(keras.layers.InputLayer(input_shape=[None,17]))\n",
    "for rate in (1,2,4,8)*2:\n",
    "    model_Full.add(keras.layers.Conv1D(filters=180,kernel_size=2,padding=\"causal\",\n",
    "                                 activation='relu',dilation_rate=rate))\n",
    "model_Full.add(keras.layers.Conv1D(filters=90,kernel_size=1))\n",
    "model_Full.compile(loss=\"mae\", optimizer='adam', metrics=[last_time_step_mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, None, 180)         6300      \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, None, 180)         64980     \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, None, 180)         64980     \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, None, 180)         64980     \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, None, 180)         64980     \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, None, 180)         64980     \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, None, 180)         64980     \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, None, 180)         64980     \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, None, 90)          16290     \n",
      "=================================================================\n",
      "Total params: 477,450\n",
      "Trainable params: 477,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_Full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 0.0017 - last_time_step_mse: 0.0018\n",
      "Epoch 00001: val_last_time_step_mse improved from inf to 0.00136, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 46s 54ms/step - loss: 0.0017 - last_time_step_mse: 0.0018 - val_loss: 0.0012 - val_last_time_step_mse: 0.0014\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 0.0010 - last_time_step_mse: 0.0011\n",
      "Epoch 00002: val_last_time_step_mse improved from 0.00136 to 0.00116, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 49s 58ms/step - loss: 0.0010 - last_time_step_mse: 0.0011 - val_loss: 0.0010 - val_last_time_step_mse: 0.0012\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 9.8499e-04 - last_time_step_mse: 0.0011\n",
      "Epoch 00003: val_last_time_step_mse improved from 0.00116 to 0.00113, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 49s 58ms/step - loss: 9.8499e-04 - last_time_step_mse: 0.0011 - val_loss: 9.8517e-04 - val_last_time_step_mse: 0.0011\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 9.6937e-04 - last_time_step_mse: 0.0011\n",
      "Epoch 00004: val_last_time_step_mse did not improve from 0.00113\n",
      "840/840 [==============================] - 42s 50ms/step - loss: 9.6937e-04 - last_time_step_mse: 0.0011 - val_loss: 0.0011 - val_last_time_step_mse: 0.0012\n",
      "Epoch 5/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 9.5661e-04 - last_time_step_mse: 0.0010\n",
      "Epoch 00005: val_last_time_step_mse improved from 0.00113 to 0.00112, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 42s 50ms/step - loss: 9.5685e-04 - last_time_step_mse: 0.0010 - val_loss: 9.8144e-04 - val_last_time_step_mse: 0.0011\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 9.4871e-04 - last_time_step_mse: 0.0010\n",
      "Epoch 00006: val_last_time_step_mse did not improve from 0.00112\n",
      "840/840 [==============================] - 47s 56ms/step - loss: 9.4871e-04 - last_time_step_mse: 0.0010 - val_loss: 9.8794e-04 - val_last_time_step_mse: 0.0011\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 9.3728e-04 - last_time_step_mse: 0.0010\n",
      "Epoch 00007: val_last_time_step_mse improved from 0.00112 to 0.00110, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 46s 55ms/step - loss: 9.3728e-04 - last_time_step_mse: 0.0010 - val_loss: 9.6653e-04 - val_last_time_step_mse: 0.0011\n",
      "Epoch 8/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 9.2584e-04 - last_time_step_mse: 0.0010\n",
      "Epoch 00008: val_last_time_step_mse did not improve from 0.00110\n",
      "840/840 [==============================] - 46s 54ms/step - loss: 9.2589e-04 - last_time_step_mse: 0.0010 - val_loss: 9.9292e-04 - val_last_time_step_mse: 0.0012\n",
      "Epoch 9/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 9.2299e-04 - last_time_step_mse: 0.0010\n",
      "Epoch 00009: val_last_time_step_mse improved from 0.00110 to 0.00104, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 46s 54ms/step - loss: 9.2265e-04 - last_time_step_mse: 0.0010 - val_loss: 9.1421e-04 - val_last_time_step_mse: 0.0010\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 9.0888e-04 - last_time_step_mse: 9.9267e-04\n",
      "Epoch 00010: val_last_time_step_mse did not improve from 0.00104\n",
      "840/840 [==============================] - 43s 51ms/step - loss: 9.0888e-04 - last_time_step_mse: 9.9267e-04 - val_loss: 9.2704e-04 - val_last_time_step_mse: 0.0010\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 9.0218e-04 - last_time_step_mse: 9.8493e-04\n",
      "Epoch 00011: val_last_time_step_mse improved from 0.00104 to 0.00102, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 40s 48ms/step - loss: 9.0218e-04 - last_time_step_mse: 9.8493e-04 - val_loss: 8.9586e-04 - val_last_time_step_mse: 0.0010\n",
      "Epoch 12/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 9.1261e-04 - last_time_step_mse: 9.9300e-04\n",
      "Epoch 00012: val_last_time_step_mse did not improve from 0.00102\n",
      "840/840 [==============================] - 45s 53ms/step - loss: 9.1206e-04 - last_time_step_mse: 9.9266e-04 - val_loss: 9.1870e-04 - val_last_time_step_mse: 0.0010\n",
      "Epoch 13/100\n",
      "838/840 [============================>.] - ETA: 0s - loss: 8.9695e-04 - last_time_step_mse: 9.7798e-04\n",
      "Epoch 00013: val_last_time_step_mse did not improve from 0.00102\n",
      "840/840 [==============================] - 32s 38ms/step - loss: 8.9647e-04 - last_time_step_mse: 9.7724e-04 - val_loss: 9.0212e-04 - val_last_time_step_mse: 0.0010\n",
      "Epoch 14/100\n",
      "838/840 [============================>.] - ETA: 0s - loss: 8.8697e-04 - last_time_step_mse: 9.6492e-04\n",
      "Epoch 00014: val_last_time_step_mse improved from 0.00102 to 0.00100, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 22s 26ms/step - loss: 8.8784e-04 - last_time_step_mse: 9.6576e-04 - val_loss: 9.0310e-04 - val_last_time_step_mse: 9.9937e-04\n",
      "Epoch 15/100\n",
      "838/840 [============================>.] - ETA: 0s - loss: 8.8901e-04 - last_time_step_mse: 9.6888e-04\n",
      "Epoch 00015: val_last_time_step_mse did not improve from 0.00100\n",
      "840/840 [==============================] - 24s 29ms/step - loss: 8.8878e-04 - last_time_step_mse: 9.6833e-04 - val_loss: 8.8774e-04 - val_last_time_step_mse: 0.0010\n",
      "Epoch 16/100\n",
      "838/840 [============================>.] - ETA: 0s - loss: 8.8278e-04 - last_time_step_mse: 9.6248e-04\n",
      "Epoch 00016: val_last_time_step_mse improved from 0.00100 to 0.00099, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 25s 30ms/step - loss: 8.8221e-04 - last_time_step_mse: 9.6192e-04 - val_loss: 8.8208e-04 - val_last_time_step_mse: 9.9421e-04\n",
      "Epoch 17/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.7874e-04 - last_time_step_mse: 9.5887e-04\n",
      "Epoch 00017: val_last_time_step_mse did not improve from 0.00099\n",
      "840/840 [==============================] - 27s 32ms/step - loss: 8.7847e-04 - last_time_step_mse: 9.5875e-04 - val_loss: 9.0238e-04 - val_last_time_step_mse: 0.0010\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.7462e-04 - last_time_step_mse: 9.5338e-04\n",
      "Epoch 00018: val_last_time_step_mse improved from 0.00099 to 0.00097, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 24s 29ms/step - loss: 8.7462e-04 - last_time_step_mse: 9.5338e-04 - val_loss: 8.5684e-04 - val_last_time_step_mse: 9.7218e-04\n",
      "Epoch 19/100\n",
      "838/840 [============================>.] - ETA: 0s - loss: 8.7706e-04 - last_time_step_mse: 9.5798e-04\n",
      "Epoch 00019: val_last_time_step_mse did not improve from 0.00097\n",
      "840/840 [==============================] - 25s 30ms/step - loss: 8.7710e-04 - last_time_step_mse: 9.5766e-04 - val_loss: 9.3927e-04 - val_last_time_step_mse: 0.0010\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.6955e-04 - last_time_step_mse: 9.4798e-04\n",
      "Epoch 00020: val_last_time_step_mse improved from 0.00097 to 0.00097, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 25s 29ms/step - loss: 8.6955e-04 - last_time_step_mse: 9.4798e-04 - val_loss: 8.7036e-04 - val_last_time_step_mse: 9.6922e-04\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.6750e-04 - last_time_step_mse: 9.4652e-04\n",
      "Epoch 00021: val_last_time_step_mse did not improve from 0.00097\n",
      "840/840 [==============================] - 24s 28ms/step - loss: 8.6750e-04 - last_time_step_mse: 9.4652e-04 - val_loss: 8.8330e-04 - val_last_time_step_mse: 9.8019e-04\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.6858e-04 - last_time_step_mse: 9.4720e-04\n",
      "Epoch 00022: val_last_time_step_mse did not improve from 0.00097\n",
      "840/840 [==============================] - 24s 29ms/step - loss: 8.6858e-04 - last_time_step_mse: 9.4720e-04 - val_loss: 9.8089e-04 - val_last_time_step_mse: 0.0011\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839/840 [============================>.] - ETA: 0s - loss: 8.5880e-04 - last_time_step_mse: 9.3823e-04\n",
      "Epoch 00023: val_last_time_step_mse improved from 0.00097 to 0.00096, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 23s 28ms/step - loss: 8.5961e-04 - last_time_step_mse: 9.3940e-04 - val_loss: 8.5873e-04 - val_last_time_step_mse: 9.5878e-04\n",
      "Epoch 24/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.5461e-04 - last_time_step_mse: 9.3461e-04 ETA: 0s - loss: 8.5613e-04 - last_time_st\n",
      "Epoch 00024: val_last_time_step_mse did not improve from 0.00096\n",
      "840/840 [==============================] - 26s 31ms/step - loss: 8.5434e-04 - last_time_step_mse: 9.3428e-04 - val_loss: 8.6884e-04 - val_last_time_step_mse: 9.9185e-04\n",
      "Epoch 25/100\n",
      "838/840 [============================>.] - ETA: 0s - loss: 8.5792e-04 - last_time_step_mse: 9.3775e-04\n",
      "Epoch 00025: val_last_time_step_mse did not improve from 0.00096\n",
      "840/840 [==============================] - 31s 36ms/step - loss: 8.5787e-04 - last_time_step_mse: 9.3738e-04 - val_loss: 8.5774e-04 - val_last_time_step_mse: 9.7030e-04\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.5059e-04 - last_time_step_mse: 9.3010e-04\n",
      "Epoch 00026: val_last_time_step_mse did not improve from 0.00096\n",
      "840/840 [==============================] - 27s 33ms/step - loss: 8.5059e-04 - last_time_step_mse: 9.3010e-04 - val_loss: 8.7408e-04 - val_last_time_step_mse: 9.6778e-04\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.5043e-04 - last_time_step_mse: 9.3002e-04\n",
      "Epoch 00027: val_last_time_step_mse did not improve from 0.00096\n",
      "840/840 [==============================] - 28s 33ms/step - loss: 8.5043e-04 - last_time_step_mse: 9.3002e-04 - val_loss: 8.8671e-04 - val_last_time_step_mse: 0.0010\n",
      "Epoch 28/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.4341e-04 - last_time_step_mse: 9.2283e-04\n",
      "Epoch 00028: val_last_time_step_mse improved from 0.00096 to 0.00096, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 28s 34ms/step - loss: 8.4317e-04 - last_time_step_mse: 9.2238e-04 - val_loss: 8.4168e-04 - val_last_time_step_mse: 9.5829e-04\n",
      "Epoch 29/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.4185e-04 - last_time_step_mse: 9.2168e-04\n",
      "Epoch 00029: val_last_time_step_mse improved from 0.00096 to 0.00094, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 28s 33ms/step - loss: 8.4189e-04 - last_time_step_mse: 9.2188e-04 - val_loss: 8.3922e-04 - val_last_time_step_mse: 9.4352e-04\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.4082e-04 - last_time_step_mse: 9.2239e-04\n",
      "Epoch 00030: val_last_time_step_mse did not improve from 0.00094\n",
      "840/840 [==============================] - 31s 37ms/step - loss: 8.4082e-04 - last_time_step_mse: 9.2239e-04 - val_loss: 8.6514e-04 - val_last_time_step_mse: 9.8017e-04\n",
      "Epoch 31/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.3916e-04 - last_time_step_mse: 9.2152e-04\n",
      "Epoch 00031: val_last_time_step_mse did not improve from 0.00094\n",
      "840/840 [==============================] - 31s 37ms/step - loss: 8.3890e-04 - last_time_step_mse: 9.2100e-04 - val_loss: 8.5778e-04 - val_last_time_step_mse: 9.6203e-04\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.3343e-04 - last_time_step_mse: 9.1400e-04\n",
      "Epoch 00032: val_last_time_step_mse improved from 0.00094 to 0.00094, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 31s 36ms/step - loss: 8.3343e-04 - last_time_step_mse: 9.1400e-04 - val_loss: 8.3274e-04 - val_last_time_step_mse: 9.4189e-04\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.3246e-04 - last_time_step_mse: 9.1520e-04\n",
      "Epoch 00033: val_last_time_step_mse did not improve from 0.00094\n",
      "840/840 [==============================] - 33s 40ms/step - loss: 8.3246e-04 - last_time_step_mse: 9.1520e-04 - val_loss: 8.5094e-04 - val_last_time_step_mse: 9.5774e-04\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.3063e-04 - last_time_step_mse: 9.1157e-04\n",
      "Epoch 00034: val_last_time_step_mse did not improve from 0.00094\n",
      "840/840 [==============================] - 31s 36ms/step - loss: 8.3063e-04 - last_time_step_mse: 9.1157e-04 - val_loss: 8.4495e-04 - val_last_time_step_mse: 9.4363e-04\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.2776e-04 - last_time_step_mse: 9.0835e-04\n",
      "Epoch 00035: val_last_time_step_mse did not improve from 0.00094\n",
      "840/840 [==============================] - 34s 40ms/step - loss: 8.2776e-04 - last_time_step_mse: 9.0835e-04 - val_loss: 8.6784e-04 - val_last_time_step_mse: 9.9355e-04\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.2737e-04 - last_time_step_mse: 9.0867e-04\n",
      "Epoch 00036: val_last_time_step_mse did not improve from 0.00094\n",
      "840/840 [==============================] - 34s 41ms/step - loss: 8.2737e-04 - last_time_step_mse: 9.0867e-04 - val_loss: 8.3731e-04 - val_last_time_step_mse: 9.4225e-04\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.2762e-04 - last_time_step_mse: 9.0735e-04\n",
      "Epoch 00037: val_last_time_step_mse did not improve from 0.00094\n",
      "840/840 [==============================] - 29s 35ms/step - loss: 8.2762e-04 - last_time_step_mse: 9.0735e-04 - val_loss: 8.3757e-04 - val_last_time_step_mse: 9.4711e-04\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.2609e-04 - last_time_step_mse: 9.0753e-04\n",
      "Epoch 00038: val_last_time_step_mse did not improve from 0.00094\n",
      "840/840 [==============================] - 30s 36ms/step - loss: 8.2609e-04 - last_time_step_mse: 9.0753e-04 - val_loss: 8.7021e-04 - val_last_time_step_mse: 9.6962e-04\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.3288e-04 - last_time_step_mse: 9.1343e-04\n",
      "Epoch 00039: val_last_time_step_mse improved from 0.00094 to 0.00093, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 32s 38ms/step - loss: 8.3288e-04 - last_time_step_mse: 9.1343e-04 - val_loss: 8.3265e-04 - val_last_time_step_mse: 9.3154e-04\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.2130e-04 - last_time_step_mse: 9.0211e-04\n",
      "Epoch 00040: val_last_time_step_mse did not improve from 0.00093\n",
      "840/840 [==============================] - 32s 38ms/step - loss: 8.2130e-04 - last_time_step_mse: 9.0211e-04 - val_loss: 8.4877e-04 - val_last_time_step_mse: 9.4345e-04\n",
      "Epoch 41/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.2021e-04 - last_time_step_mse: 9.0158e-04\n",
      "Epoch 00041: val_last_time_step_mse did not improve from 0.00093\n",
      "840/840 [==============================] - 31s 37ms/step - loss: 8.2077e-04 - last_time_step_mse: 9.0251e-04 - val_loss: 8.3090e-04 - val_last_time_step_mse: 9.4286e-04\n",
      "Epoch 42/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.1865e-04 - last_time_step_mse: 8.9843e-04\n",
      "Epoch 00042: val_last_time_step_mse did not improve from 0.00093\n",
      "840/840 [==============================] - 33s 39ms/step - loss: 8.1871e-04 - last_time_step_mse: 8.9831e-04 - val_loss: 8.3012e-04 - val_last_time_step_mse: 9.4622e-04\n",
      "Epoch 43/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.1599e-04 - last_time_step_mse: 8.9659e-04\n",
      "Epoch 00043: val_last_time_step_mse improved from 0.00093 to 0.00093, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 31s 37ms/step - loss: 8.1594e-04 - last_time_step_mse: 8.9667e-04 - val_loss: 8.2323e-04 - val_last_time_step_mse: 9.3114e-04\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.1752e-04 - last_time_step_mse: 8.9905e-04\n",
      "Epoch 00044: val_last_time_step_mse did not improve from 0.00093\n",
      "840/840 [==============================] - 33s 39ms/step - loss: 8.1752e-04 - last_time_step_mse: 8.9905e-04 - val_loss: 8.9021e-04 - val_last_time_step_mse: 0.0010\n",
      "Epoch 45/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.1502e-04 - last_time_step_mse: 8.9577e-04\n",
      "Epoch 00045: val_last_time_step_mse did not improve from 0.00093\n",
      "840/840 [==============================] - 31s 37ms/step - loss: 8.1546e-04 - last_time_step_mse: 8.9608e-04 - val_loss: 8.6158e-04 - val_last_time_step_mse: 9.6709e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.1239e-04 - last_time_step_mse: 8.9348e-04\n",
      "Epoch 00046: val_last_time_step_mse did not improve from 0.00093\n",
      "840/840 [==============================] - 31s 36ms/step - loss: 8.1239e-04 - last_time_step_mse: 8.9348e-04 - val_loss: 8.3479e-04 - val_last_time_step_mse: 9.5121e-04\n",
      "Epoch 47/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.1354e-04 - last_time_step_mse: 8.9470e-04\n",
      "Epoch 00047: val_last_time_step_mse did not improve from 0.00093\n",
      "840/840 [==============================] - 30s 36ms/step - loss: 8.1402e-04 - last_time_step_mse: 8.9508e-04 - val_loss: 8.4693e-04 - val_last_time_step_mse: 9.6729e-04\n",
      "Epoch 48/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.1528e-04 - last_time_step_mse: 8.9573e-04\n",
      "Epoch 00048: val_last_time_step_mse did not improve from 0.00093\n",
      "840/840 [==============================] - 30s 36ms/step - loss: 8.1533e-04 - last_time_step_mse: 8.9567e-04 - val_loss: 8.6502e-04 - val_last_time_step_mse: 9.7327e-04\n",
      "Epoch 49/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.0754e-04 - last_time_step_mse: 8.8796e-04\n",
      "Epoch 00049: val_last_time_step_mse improved from 0.00093 to 0.00093, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 30s 36ms/step - loss: 8.0785e-04 - last_time_step_mse: 8.8787e-04 - val_loss: 8.3928e-04 - val_last_time_step_mse: 9.3069e-04\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.1168e-04 - last_time_step_mse: 8.9277e-04\n",
      "Epoch 00050: val_last_time_step_mse improved from 0.00093 to 0.00092, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 30s 36ms/step - loss: 8.1168e-04 - last_time_step_mse: 8.9277e-04 - val_loss: 8.2170e-04 - val_last_time_step_mse: 9.1924e-04\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.0868e-04 - last_time_step_mse: 8.8879e-04\n",
      "Epoch 00051: val_last_time_step_mse did not improve from 0.00092\n",
      "840/840 [==============================] - 27s 32ms/step - loss: 8.0868e-04 - last_time_step_mse: 8.8879e-04 - val_loss: 8.2521e-04 - val_last_time_step_mse: 9.3934e-04\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.0507e-04 - last_time_step_mse: 8.8645e-04\n",
      "Epoch 00052: val_last_time_step_mse did not improve from 0.00092\n",
      "840/840 [==============================] - 29s 35ms/step - loss: 8.0507e-04 - last_time_step_mse: 8.8645e-04 - val_loss: 8.3888e-04 - val_last_time_step_mse: 9.5661e-04\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.0952e-04 - last_time_step_mse: 8.8946e-04\n",
      "Epoch 00053: val_last_time_step_mse did not improve from 0.00092\n",
      "840/840 [==============================] - 33s 40ms/step - loss: 8.0952e-04 - last_time_step_mse: 8.8946e-04 - val_loss: 8.1272e-04 - val_last_time_step_mse: 9.2448e-04\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.0443e-04 - last_time_step_mse: 8.8551e-04\n",
      "Epoch 00054: val_last_time_step_mse did not improve from 0.00092\n",
      "840/840 [==============================] - 37s 44ms/step - loss: 8.0443e-04 - last_time_step_mse: 8.8551e-04 - val_loss: 8.5627e-04 - val_last_time_step_mse: 9.3963e-04\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 8.0714e-04 - last_time_step_mse: 8.8741e-04\n",
      "Epoch 00055: val_last_time_step_mse did not improve from 0.00092\n",
      "840/840 [==============================] - 36s 42ms/step - loss: 8.0714e-04 - last_time_step_mse: 8.8741e-04 - val_loss: 8.1978e-04 - val_last_time_step_mse: 9.3427e-04\n",
      "Epoch 56/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.0460e-04 - last_time_step_mse: 8.8529e-04\n",
      "Epoch 00056: val_last_time_step_mse did not improve from 0.00092\n",
      "840/840 [==============================] - 32s 39ms/step - loss: 8.0417e-04 - last_time_step_mse: 8.8480e-04 - val_loss: 8.1695e-04 - val_last_time_step_mse: 9.2499e-04\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.9873e-04 - last_time_step_mse: 8.7999e-04\n",
      "Epoch 00057: val_last_time_step_mse improved from 0.00092 to 0.00091, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 35s 42ms/step - loss: 7.9873e-04 - last_time_step_mse: 8.7999e-04 - val_loss: 8.1525e-04 - val_last_time_step_mse: 9.0576e-04\n",
      "Epoch 58/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.0435e-04 - last_time_step_mse: 8.8520e-04\n",
      "Epoch 00058: val_last_time_step_mse did not improve from 0.00091\n",
      "840/840 [==============================] - 36s 43ms/step - loss: 8.0453e-04 - last_time_step_mse: 8.8519e-04 - val_loss: 8.2235e-04 - val_last_time_step_mse: 9.2353e-04\n",
      "Epoch 59/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.0085e-04 - last_time_step_mse: 8.8038e-04\n",
      "Epoch 00059: val_last_time_step_mse improved from 0.00091 to 0.00090, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 35s 42ms/step - loss: 8.0134e-04 - last_time_step_mse: 8.8137e-04 - val_loss: 7.9687e-04 - val_last_time_step_mse: 9.0132e-04\n",
      "Epoch 60/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.9975e-04 - last_time_step_mse: 8.8127e-04\n",
      "Epoch 00060: val_last_time_step_mse improved from 0.00090 to 0.00090, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 32s 38ms/step - loss: 7.9970e-04 - last_time_step_mse: 8.8105e-04 - val_loss: 7.9944e-04 - val_last_time_step_mse: 8.9903e-04\n",
      "Epoch 61/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.0622e-04 - last_time_step_mse: 8.8790e-04\n",
      "Epoch 00061: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 35s 42ms/step - loss: 8.0605e-04 - last_time_step_mse: 8.8759e-04 - val_loss: 8.0995e-04 - val_last_time_step_mse: 9.1960e-04\n",
      "Epoch 62/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.0021e-04 - last_time_step_mse: 8.8160e-04\n",
      "Epoch 00062: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 32s 38ms/step - loss: 7.9977e-04 - last_time_step_mse: 8.8103e-04 - val_loss: 8.5985e-04 - val_last_time_step_mse: 9.6583e-04\n",
      "Epoch 63/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.0104e-04 - last_time_step_mse: 8.8317e-04\n",
      "Epoch 00063: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 31s 37ms/step - loss: 8.0079e-04 - last_time_step_mse: 8.8283e-04 - val_loss: 8.3338e-04 - val_last_time_step_mse: 9.4800e-04\n",
      "Epoch 64/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.9429e-04 - last_time_step_mse: 8.7625e-04\n",
      "Epoch 00064: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 34s 40ms/step - loss: 7.9380e-04 - last_time_step_mse: 8.7564e-04 - val_loss: 8.0547e-04 - val_last_time_step_mse: 9.0497e-04\n",
      "Epoch 65/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.9850e-04 - last_time_step_mse: 8.8001e-04\n",
      "Epoch 00065: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 34s 40ms/step - loss: 7.9851e-04 - last_time_step_mse: 8.7996e-04 - val_loss: 8.0560e-04 - val_last_time_step_mse: 9.0226e-04\n",
      "Epoch 66/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 8.0020e-04 - last_time_step_mse: 8.8024e-04\n",
      "Epoch 00066: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 34s 40ms/step - loss: 8.0022e-04 - last_time_step_mse: 8.8054e-04 - val_loss: 8.6852e-04 - val_last_time_step_mse: 9.9670e-04\n",
      "Epoch 67/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.9535e-04 - last_time_step_mse: 8.7575e-04\n",
      "Epoch 00067: val_last_time_step_mse improved from 0.00090 to 0.00090, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 35s 42ms/step - loss: 7.9583e-04 - last_time_step_mse: 8.7634e-04 - val_loss: 7.9925e-04 - val_last_time_step_mse: 8.9535e-04\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - ETA: 0s - loss: 7.9726e-04 - last_time_step_mse: 8.7916e-04\n",
      "Epoch 00068: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 32s 38ms/step - loss: 7.9726e-04 - last_time_step_mse: 8.7916e-04 - val_loss: 8.1887e-04 - val_last_time_step_mse: 9.0780e-04\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.9597e-04 - last_time_step_mse: 8.7797e-04\n",
      "Epoch 00069: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 36s 43ms/step - loss: 7.9597e-04 - last_time_step_mse: 8.7797e-04 - val_loss: 8.8395e-04 - val_last_time_step_mse: 9.9924e-04\n",
      "Epoch 70/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.9608e-04 - last_time_step_mse: 8.7840e-04\n",
      "Epoch 00070: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 34s 40ms/step - loss: 7.9630e-04 - last_time_step_mse: 8.7846e-04 - val_loss: 8.0516e-04 - val_last_time_step_mse: 9.0929e-04\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.9143e-04 - last_time_step_mse: 8.7258e-04\n",
      "Epoch 00071: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 34s 41ms/step - loss: 7.9143e-04 - last_time_step_mse: 8.7258e-04 - val_loss: 0.0010 - val_last_time_step_mse: 0.0012\n",
      "Epoch 72/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.9530e-04 - last_time_step_mse: 8.7775e-04\n",
      "Epoch 00072: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 35s 41ms/step - loss: 7.9555e-04 - last_time_step_mse: 8.7809e-04 - val_loss: 8.1801e-04 - val_last_time_step_mse: 9.1925e-04\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.9133e-04 - last_time_step_mse: 8.7307e-04\n",
      "Epoch 00073: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 35s 41ms/step - loss: 7.9133e-04 - last_time_step_mse: 8.7307e-04 - val_loss: 8.3027e-04 - val_last_time_step_mse: 9.4306e-04\n",
      "Epoch 74/100\n",
      "838/840 [============================>.] - ETA: 0s - loss: 7.9197e-04 - last_time_step_mse: 8.7356e-04\n",
      "Epoch 00074: val_last_time_step_mse did not improve from 0.00090\n",
      "840/840 [==============================] - 33s 39ms/step - loss: 7.9183e-04 - last_time_step_mse: 8.7345e-04 - val_loss: 7.9895e-04 - val_last_time_step_mse: 9.0153e-04\n",
      "Epoch 75/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.8993e-04 - last_time_step_mse: 8.7101e-04\n",
      "Epoch 00075: val_last_time_step_mse improved from 0.00090 to 0.00089, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 31s 37ms/step - loss: 7.9008e-04 - last_time_step_mse: 8.7167e-04 - val_loss: 7.9740e-04 - val_last_time_step_mse: 8.9300e-04\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.9901e-04 - last_time_step_mse: 8.7994e-04\n",
      "Epoch 00076: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 34s 41ms/step - loss: 7.9901e-04 - last_time_step_mse: 8.7994e-04 - val_loss: 7.9914e-04 - val_last_time_step_mse: 9.0250e-04\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.9402e-04 - last_time_step_mse: 8.7410e-04\n",
      "Epoch 00077: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 35s 42ms/step - loss: 7.9402e-04 - last_time_step_mse: 8.7410e-04 - val_loss: 8.1824e-04 - val_last_time_step_mse: 9.1359e-04\n",
      "Epoch 78/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.9131e-04 - last_time_step_mse: 8.7146e-04\n",
      "Epoch 00078: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 33s 39ms/step - loss: 7.9162e-04 - last_time_step_mse: 8.7308e-04 - val_loss: 8.1579e-04 - val_last_time_step_mse: 9.1136e-04\n",
      "Epoch 79/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.8723e-04 - last_time_step_mse: 8.6891e-04\n",
      "Epoch 00079: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 32s 38ms/step - loss: 7.8809e-04 - last_time_step_mse: 8.6932e-04 - val_loss: 8.0013e-04 - val_last_time_step_mse: 9.0485e-04\n",
      "Epoch 80/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.8722e-04 - last_time_step_mse: 8.6711e-04\n",
      "Epoch 00080: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 33s 40ms/step - loss: 7.8758e-04 - last_time_step_mse: 8.6789e-04 - val_loss: 8.0538e-04 - val_last_time_step_mse: 9.1659e-04\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.9193e-04 - last_time_step_mse: 8.7259e-04\n",
      "Epoch 00081: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 32s 38ms/step - loss: 7.9193e-04 - last_time_step_mse: 8.7259e-04 - val_loss: 8.0098e-04 - val_last_time_step_mse: 9.0221e-04\n",
      "Epoch 82/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.8794e-04 - last_time_step_mse: 8.6951e-04\n",
      "Epoch 00082: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 37s 44ms/step - loss: 7.8768e-04 - last_time_step_mse: 8.6907e-04 - val_loss: 8.0269e-04 - val_last_time_step_mse: 9.1053e-04\n",
      "Epoch 83/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.8944e-04 - last_time_step_mse: 8.7073e-04\n",
      "Epoch 00083: val_last_time_step_mse improved from 0.00089 to 0.00089, saving model to Checkpoint/Wavenet(180_90_1).h5\n",
      "840/840 [==============================] - 33s 39ms/step - loss: 7.8911e-04 - last_time_step_mse: 8.7008e-04 - val_loss: 7.9596e-04 - val_last_time_step_mse: 8.8875e-04\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.8352e-04 - last_time_step_mse: 8.6393e-04\n",
      "Epoch 00084: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 34s 41ms/step - loss: 7.8352e-04 - last_time_step_mse: 8.6393e-04 - val_loss: 8.0576e-04 - val_last_time_step_mse: 8.9835e-04\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.8745e-04 - last_time_step_mse: 8.6886e-04\n",
      "Epoch 00085: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 35s 41ms/step - loss: 7.8745e-04 - last_time_step_mse: 8.6886e-04 - val_loss: 7.9652e-04 - val_last_time_step_mse: 9.0196e-04\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.8583e-04 - last_time_step_mse: 8.6698e-04\n",
      "Epoch 00086: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 30s 36ms/step - loss: 7.8583e-04 - last_time_step_mse: 8.6698e-04 - val_loss: 7.9830e-04 - val_last_time_step_mse: 9.0397e-04\n",
      "Epoch 87/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.8575e-04 - last_time_step_mse: 8.6641e-04\n",
      "Epoch 00087: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 37s 43ms/step - loss: 7.8595e-04 - last_time_step_mse: 8.6661e-04 - val_loss: 8.0096e-04 - val_last_time_step_mse: 9.0086e-04\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.9060e-04 - last_time_step_mse: 8.7011e-04\n",
      "Epoch 00088: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 36s 43ms/step - loss: 7.9060e-04 - last_time_step_mse: 8.7011e-04 - val_loss: 8.2054e-04 - val_last_time_step_mse: 9.1457e-04\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.8459e-04 - last_time_step_mse: 8.6582e-04\n",
      "Epoch 00089: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 37s 44ms/step - loss: 7.8459e-04 - last_time_step_mse: 8.6582e-04 - val_loss: 8.0192e-04 - val_last_time_step_mse: 9.1283e-04\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.8682e-04 - last_time_step_mse: 8.6716e-04\n",
      "Epoch 00090: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 35s 42ms/step - loss: 7.8682e-04 - last_time_step_mse: 8.6716e-04 - val_loss: 8.0963e-04 - val_last_time_step_mse: 9.2266e-04\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - ETA: 0s - loss: 7.8300e-04 - last_time_step_mse: 8.6344e-04\n",
      "Epoch 00091: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 32s 39ms/step - loss: 7.8300e-04 - last_time_step_mse: 8.6344e-04 - val_loss: 8.1696e-04 - val_last_time_step_mse: 9.3137e-04\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.8271e-04 - last_time_step_mse: 8.6354e-04\n",
      "Epoch 00092: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 33s 39ms/step - loss: 7.8271e-04 - last_time_step_mse: 8.6354e-04 - val_loss: 8.3771e-04 - val_last_time_step_mse: 9.3639e-04\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.8433e-04 - last_time_step_mse: 8.6482e-04\n",
      "Epoch 00093: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 31s 37ms/step - loss: 7.8433e-04 - last_time_step_mse: 8.6482e-04 - val_loss: 7.9435e-04 - val_last_time_step_mse: 8.9850e-04\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.8554e-04 - last_time_step_mse: 8.6607e-04\n",
      "Epoch 00094: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 30s 36ms/step - loss: 7.8554e-04 - last_time_step_mse: 8.6607e-04 - val_loss: 8.3888e-04 - val_last_time_step_mse: 9.2934e-04\n",
      "Epoch 95/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.8563e-04 - last_time_step_mse: 8.6704e-04\n",
      "Epoch 00095: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 33s 39ms/step - loss: 7.8645e-04 - last_time_step_mse: 8.6810e-04 - val_loss: 7.9434e-04 - val_last_time_step_mse: 9.0396e-04\n",
      "Epoch 96/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 7.8241e-04 - last_time_step_mse: 8.6258e-04\n",
      "Epoch 00096: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 31s 37ms/step - loss: 7.8223e-04 - last_time_step_mse: 8.6269e-04 - val_loss: 8.2148e-04 - val_last_time_step_mse: 9.3331e-04\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.8138e-04 - last_time_step_mse: 8.6258e-04\n",
      "Epoch 00097: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 28s 33ms/step - loss: 7.8138e-04 - last_time_step_mse: 8.6258e-04 - val_loss: 8.0297e-04 - val_last_time_step_mse: 9.1272e-04\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - ETA: 0s - loss: 7.8607e-04 - last_time_step_mse: 8.6681e-04\n",
      "Epoch 00098: val_last_time_step_mse did not improve from 0.00089\n",
      "840/840 [==============================] - 33s 39ms/step - loss: 7.8607e-04 - last_time_step_mse: 8.6681e-04 - val_loss: 8.5486e-04 - val_last_time_step_mse: 9.3713e-04\n"
     ]
    }
   ],
   "source": [
    "history_Full= model_Full.fit(X_train_scaled, y_train_scaled, epochs=100,\n",
    "                    validation_data=(X_valid_scaled,y_valid_scaled),callbacks=callback_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Full.history['last_time_step_mse'], label='train_loss')\n",
    "plt.plot(history_Full.history['val_last_time_step_mse'], label='val_loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 마무리(filter_size180해야함)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cancer",
   "language": "python",
   "name": "cancer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
