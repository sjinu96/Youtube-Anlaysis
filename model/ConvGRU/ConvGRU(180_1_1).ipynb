{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T03:17:33.191705Z",
     "start_time": "2020-11-20T03:17:33.186707Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, date\n",
    "from sklearn import utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def _fit_transform(self, raw):\n",
    "        result = raw.copy()\n",
    "\n",
    "        result = self._n_comment_to_float(result)\n",
    "        result = self._str_to_datetype(result)\n",
    "        result = self._add_n_hashtag(result)\n",
    "        \n",
    "        self.non_numeric = ['channel', 'title', 'genre', 'description', 'date', 'sign_in']\n",
    "        result = self._merge(result, self.non_numeric)\n",
    "        \n",
    "        features = ['cumul_view', 'n_dislike', 'n_like', 'n_comment', 'video_n_view', 'cumul_subs']\n",
    "        new_name = ['view_diff', 'dislike_diff', 'like_diff', 'comment_diff', 'video_n_view_diff', 'sub_diff']\n",
    "        result = self._add_diff(result, features, new_name)\n",
    "        \n",
    "        result = self._add_no_upload_interval(result)\n",
    "        result = self._remove_nan(result)\n",
    "        self._one_hot(result)\n",
    "\n",
    "        return result\n",
    "        \n",
    "        \n",
    "        \n",
    "    #FEATRUES TO ADD & MODIFY\n",
    "    ####################################################################     \n",
    "    def _n_comment_to_float(self,result):\n",
    "        idx1 = result['n_comment'] == '댓글 사용 중지'\n",
    "        idx2 = result.n_comment.isna()\n",
    "        idx = idx1|idx2\n",
    "        result['n_comment'].loc[idx] = result['n_comment'].loc[idx].apply(lambda x: 0)\n",
    "        result['n_comment'] = result['n_comment'].astype(float)\n",
    "        return result\n",
    "        \n",
    "    \n",
    "    def _str_to_datetype(self,result):\n",
    "        if pd.api.types.is_datetime64_ns_dtype(result['date']):\n",
    "            pass\n",
    "        else:\n",
    "            result['date'] = pd.to_datetime(result['date'])\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def _add_n_hashtag(self,result):\n",
    "        result['n_hashtage'] = 0\n",
    "        idx = result['description'].notnull()\n",
    "        result.loc[idx, 'n_hashtage'] = result.loc[idx, 'description'].apply(lambda x: len(x.split('#'))-1)\n",
    "        return result\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_to_merge(data, numeric, non_numeric):\n",
    "        data = data.reset_index(drop=True)\n",
    "        num_to_add = data.title.shape[0] - data.title.isna().sum()\n",
    "        data = pd.concat((data.loc[0,non_numeric], data[numeric].mean()))\n",
    "        data['video_num'] = num_to_add\n",
    "        return data\n",
    "    def _merge(self, result, non_numeric):\n",
    "        #operate both merge and creating video_num featrue simultaneously.\n",
    "        numeric = [col for col in result.columns.tolist() if col not in non_numeric]\n",
    "        return result.groupby(['channel', 'date']).apply(lambda x: self._get_to_merge(x, numeric, non_numeric)).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_diff(result, feature, new_name):\n",
    "        result = result.reset_index(drop=True)\n",
    "        result[new_name] = (result[feature] - result[feature].shift())\n",
    "        return result\n",
    "    def _add_diff(self, result, feature, new_name):\n",
    "        result = result.groupby('channel').apply(lambda x: self._get_diff(x, feature, new_name)).reset_index(drop=True)\n",
    "        result[new_name] = result[new_name].fillna(0)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_no_upload_interval(result):\n",
    "        result = result.reset_index(drop=True)\n",
    "        upload_idx = result[result['video_num'] != 0].index.tolist()\n",
    "        temp = [0 for i in range(result.shape[0])]\n",
    "        for i in range(len(upload_idx)):\n",
    "            if i == len(upload_idx)-1:\n",
    "                former = upload_idx[i]\n",
    "                temp[former+1:] = [i+1 for i in range(len(temp[former+1:]))]\n",
    "            else:\n",
    "                former, latter = upload_idx[i], upload_idx[i+1]\n",
    "                temp[former+1:latter] = [i+1 for i in range(len(temp[former+1:latter]))]\n",
    "        result['no_upload_interval'] = temp\n",
    "        return result\n",
    "    def _add_no_upload_interval(self,result):\n",
    "        return result.groupby('channel').apply(lambda x: self._get_no_upload_interval(x)).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    def _remove_nan(self, result):\n",
    "        numeric = [col for col in result.columns.tolist() if col not in self.non_numeric]\n",
    "        result.loc[:, numeric] = result.loc[:,numeric].fillna(0)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def _one_hot(self, data):\n",
    "        data.loc[:,'genre'] = data.genre.fillna('etc')\n",
    "        genre = data.genre.unique().tolist()\n",
    "        for i, name in enumerate(genre):\n",
    "            data.genre[data.genre==name] = data.genre[data.genre==name].apply(lambda x: i)\n",
    "            \n",
    "        one_hot = pd.get_dummies(data.genre.unique().tolist())\n",
    "        data['one_hot'] = data.genre\n",
    "        for i in range(len(one_hot)):\n",
    "            data.loc[data.genre==i,'one_hot'] = data.loc[data.genre==i, 'genre'].apply(lambda x: one_hot[i].values)\n",
    "    ####################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    #CREATE SEQUENTIAL DATA\n",
    "    ####################################################################\n",
    "    def _extract_at_least_filter(self, result, filter_size):\n",
    "        #fillter_size 이상인 채널 추출하기\n",
    "        alive_idx = result['channel'].value_counts() >= filter_size\n",
    "        alive_array = alive_idx[alive_idx==True].index\n",
    "        return result[result['channel'].isin(alive_array)].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _to_sequential(result, filter_size, target_size, stride, features, target_features):\n",
    "        result = result.reset_index(drop=True)\n",
    "        idx_list = result.index.tolist()\n",
    "        \n",
    "        train, target = [],[]\n",
    "        for i in range((len(idx_list)-filter_size-target_size)//stride +1):\n",
    "            train_idx = idx_list[i*stride : i*stride + filter_size]\n",
    "            target_idx = idx_list[i*stride + filter_size : i*stride + filter_size + target_size]\n",
    "            train_temp = result.loc[train_idx,:].values.reshape(1,-1)\n",
    "            target_temp = result.loc[target_idx,target_features].values.reshape(1,-1)\n",
    "            \n",
    "            train = train_temp.copy() if i == 0 else np.vstack([train, train_temp])\n",
    "            target = target_temp.copy() if i == 0 else np.vstack([target, target_temp])\n",
    "            \n",
    "        train = pd.DataFrame(train, columns = result.columns.tolist()*filter_size)\n",
    "        target = pd.DataFrame(target, columns = target_features*target_size)\n",
    "        return train[features], target\n",
    "    def _create_sequential_data(self, result, filter_size=7, target_size=1, stride=1, features=None, target_features=None):\n",
    "        #remove channels with few information with respect to filter_size and target_size to extract\n",
    "        result = self._extract_at_least_filter(result, filter_size + target_size)\n",
    "        \n",
    "        #features: features to drop fromf X (features)\n",
    "        #target_features: features to extract from Y (targets)\n",
    "        if features is None:\n",
    "            features = ['date', 'genre','title', 'channel', 'description',\t'sign_in', 'current_cumul_view', 'current_n_video', 'current_cumul_subs']\n",
    "        if target_features is None:\n",
    "            target_features = ['sub_diff']\n",
    "        \n",
    "        #return train, target set wrt groups\n",
    "        result = result.groupby('channel').apply(lambda x: self._to_sequential(x, filter_size, target_size, stride, features, target_features)).reset_index(drop=True)\n",
    "        return self._combine(result)\n",
    "    \n",
    "    \n",
    "    def _combine(self, result):\n",
    "        temp0, temp1 = [], []\n",
    "        for i in range(len(result)):\n",
    "            temp0.append(result[i][0])\n",
    "            temp1.append(result[i][1])\n",
    "        temp0 = pd.concat(temp0)\n",
    "        temp1 = pd.concat(temp1)\n",
    "        return (temp0, temp1)\n",
    "    ####################################################################\n",
    "\n",
    "\n",
    "    \n",
    "    #SCALE\n",
    "    ####################################################################\n",
    "    def scale(self, data, return_original_scale=True):\n",
    "        original_scale = pd.concat((data.max(), data.min()), axis=1).T\n",
    "        original_scale.index=['max', 'min']\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "        if return_original_scale:\n",
    "            return data, original_scale\n",
    "        return data\n",
    "    \n",
    "        \n",
    "    def inverse_scale(self, pred, scl):\n",
    "        for idx in range(pred.shape[1]):\n",
    "            pred.iloc[:,idx] = (scl.iloc[0,idx]-scl.iloc[1,idx])*pred.iloc[:,idx]+scl.iloc[1,idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader(Preprocessor):\n",
    "    def __init__(self, path):\n",
    "        self._raw = pd.read_csv(path)\n",
    "        self.data = super()._fit_transform(self._raw.copy())\n",
    "        print('Data Loaded. :P')\n",
    "        \n",
    "        \n",
    "    def get_data(self, filter_size=7, target_size=1, stride=1, features=None, target_features=None,\n",
    "                         channel:list=None, shuffle=False, random_state=None, order=None):\n",
    "        if channel is None:\n",
    "            data_to_extract = self.data\n",
    "        else:\n",
    "            channels = self.list_channel[channel].tolist()\n",
    "            data_to_extract = self.data.set_index('channel').loc[channels].reset_index()\n",
    "            \n",
    "        train, target = self._create_sequential_data(data_to_extract, filter_size, target_size, stride, features, target_features)\n",
    "        if shuffle:\n",
    "            train, target = utils.shuffle(train, target, random_state=random_state)\n",
    "        \n",
    "        if order:\n",
    "            train_col = [col for col in train.columns.unique().tolist()]\n",
    "            target_col = [col for col in target.columns.unique().tolist()]\n",
    "            train, target = train[train_col], target[target_col]\n",
    "            \n",
    "        return train, target\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def list_features(self):\n",
    "        #list the entire features, hence you can choose which features are included in whole set.\n",
    "        return self.data.columns.tolist()\n",
    "    \n",
    "    @property\n",
    "    def list_channel(self):\n",
    "        #list indices of channel.\n",
    "        return pd.Series(self.data.channel.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> load함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(\n",
    "    filter_size: '60, 90, 180', \n",
    "    target_size: '1, 7, 30, 180', \n",
    "    stride: '1, 2, 3',\n",
    "    drop_suffix: '각 변수 끝에 붙은 번호를 제거할지 여부'=True,\n",
    "    path='/home/mskang/CapstoneUOS/notebooks/ModelResearch_iloveslowfood/data_variants'):\n",
    "    \n",
    "    print(f'Setting: filter_size({filter_size})\\ttarget_size({target_size})\\tstride({stride})\\tdrop_suffix({drop_suffix})')\n",
    "    X_name = f'fs({filter_size})_ts({target_size})_st({stride}).csv'\n",
    "    y_name = f'fs({filter_size})_ts({target_size})_st({stride})_label.csv'\n",
    "    \n",
    "    print('Load feature data...', end='\\t')\n",
    "    X = pd.read_csv(os.path.join(path, X_name))\n",
    "    print('loaded!')\n",
    "    print('Load label data...', end='\\t')\n",
    "    y = pd.read_csv(os.path.join(path, y_name))\n",
    "    print('loaded!')\n",
    "    \n",
    "    if drop_suffix:\n",
    "        X.columns = list(map(lambda x: x.split('.')[0], X.columns.tolist()))\n",
    "        y.columns = list(map(lambda x: x.split('.')[0], y.columns.tolist()))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting: filter_size(180)\ttarget_size(1)\tstride(1)\tdrop_suffix(True)\n",
      "Load feature data...\tloaded!\n",
      "Load label data...\tloaded!\n"
     ]
    }
   ],
   "source": [
    "filter_size = 180\n",
    "target_size = 1\n",
    "stride = 1\n",
    "X, y = load(filter_size, target_size, stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Train/Test/VAlid 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "test_size = 0.2\n",
    "\n",
    "X_trn, X_test, y_trn, y_test = train_test_split(\n",
    "    X, y, \n",
    "    shuffle=True, \n",
    "    test_size=test_size, \n",
    "    random_state=random_state\n",
    ") \n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_trn, y_trn, \n",
    "    shuffle=True, \n",
    "    test_size=test_size, \n",
    "    random_state=random_state\n",
    ") \n",
    "\n",
    "### 스케일링 필요 시 다음을 진행(타깃에 대한 스케일링은 진행되지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "# X_valid_scaled = pd.DataFrame(scaler.transform(X_valid), columns=X_valid.columns)\n",
    "# X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D TO 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_to_multi(df):\n",
    "    feature_num=len(set(df.columns))\n",
    "    window_num=int(df.shape[1]/feature_num)\n",
    "    sample_num=int(df.shape[0])\n",
    "    temp=np.empty([sample_num,window_num,feature_num])\n",
    "    for i in range(feature_num):\n",
    "        temp[:,:,i]=df.iloc[:,window_num*i:window_num*i+window_num]\n",
    "    \n",
    "    return temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>...</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "      <th>no_upload_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24830</th>\n",
       "      <td>9.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.26</td>\n",
       "      <td>146.593333</td>\n",
       "      <td>4.78</td>\n",
       "      <td>9.40</td>\n",
       "      <td>8.53</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "      <td>153</td>\n",
       "      <td>154</td>\n",
       "      <td>155</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11981</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "      <td>193</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31747</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49094</th>\n",
       "      <td>0.00</td>\n",
       "      <td>7.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.620000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48507</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82157</th>\n",
       "      <td>11.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73539</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75468</th>\n",
       "      <td>52.73</td>\n",
       "      <td>17.07</td>\n",
       "      <td>11.88</td>\n",
       "      <td>9.02</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.100000</td>\n",
       "      <td>10.78</td>\n",
       "      <td>11.08</td>\n",
       "      <td>15.57</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41133</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65317 rows × 3060 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration  duration  duration  duration  duration  duration    duration  \\\n",
       "24830      9.28      0.00      0.00      0.00       0.0    156.26  146.593333   \n",
       "24979      0.00      0.00      0.00      0.00       0.0      0.00    0.000000   \n",
       "11981      0.00      0.00      0.00      0.00       0.0      0.00    0.000000   \n",
       "31747      0.00      0.00      0.00      0.00       0.0      0.00    0.000000   \n",
       "49094      0.00      7.98      0.00     13.50       0.0      0.00    7.620000   \n",
       "...         ...       ...       ...       ...       ...       ...         ...   \n",
       "48507      0.00      0.00      0.00      0.00       0.0      0.00    0.000000   \n",
       "82157     11.35      0.00      0.00      0.00       0.0      0.00    0.000000   \n",
       "73539      0.00      0.00      0.00      0.00       0.0      0.00    0.000000   \n",
       "75468     52.73     17.07     11.88      9.02      11.4      0.00   35.100000   \n",
       "41133      0.00      0.00      0.00      0.00       0.0      4.33    0.000000   \n",
       "\n",
       "       duration  duration  duration  ...  no_upload_interval  \\\n",
       "24830      4.78      9.40      8.53  ...                   1   \n",
       "24979      0.00      0.00      0.00  ...                 150   \n",
       "11981      0.00      0.00      0.00  ...                 190   \n",
       "31747      0.00      0.00      0.00  ...                   1   \n",
       "49094      0.00     14.00      0.00  ...                   0   \n",
       "...         ...       ...       ...  ...                 ...   \n",
       "48507      0.00      0.00      0.00  ...                  84   \n",
       "82157     22.20      0.00      0.00  ...                   0   \n",
       "73539      0.00      0.00      0.00  ...                  11   \n",
       "75468     10.78     11.08     15.57  ...                   5   \n",
       "41133      0.00      0.00      0.00  ...                   1   \n",
       "\n",
       "       no_upload_interval  no_upload_interval  no_upload_interval  \\\n",
       "24830                   2                   0                   1   \n",
       "24979                 151                 152                 153   \n",
       "11981                 191                 192                 193   \n",
       "31747                   0                   0                   0   \n",
       "49094                   1                   0                   1   \n",
       "...                   ...                 ...                 ...   \n",
       "48507                  85                  86                  87   \n",
       "82157                   0                   1                   2   \n",
       "73539                   0                   1                   0   \n",
       "75468                   6                   7                   8   \n",
       "41133                   2                   3                   0   \n",
       "\n",
       "       no_upload_interval  no_upload_interval  no_upload_interval  \\\n",
       "24830                   0                   1                   2   \n",
       "24979                 154                 155                 156   \n",
       "11981                 194                 195                 196   \n",
       "31747                   1                   2                   3   \n",
       "49094                   2                   0                   1   \n",
       "...                   ...                 ...                 ...   \n",
       "48507                  88                  89                  90   \n",
       "82157                   3                   4                   5   \n",
       "73539                   1                   2                   3   \n",
       "75468                   9                  10                  11   \n",
       "41133                   1                   2                   3   \n",
       "\n",
       "       no_upload_interval  no_upload_interval  no_upload_interval  \n",
       "24830                   3                   4                   5  \n",
       "24979                 157                 158                 159  \n",
       "11981                 197                 198                 199  \n",
       "31747                   4                   5                   6  \n",
       "49094                   0                   1                   0  \n",
       "...                   ...                 ...                 ...  \n",
       "48507                  91                  92                  93  \n",
       "82157                   0                   1                   2  \n",
       "73539                   4                   5                   6  \n",
       "75468                  12                  13                  14  \n",
       "41133                   0                   1                   2  \n",
       "\n",
       "[65317 rows x 3060 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3d=stack_to_multi(X_train)\n",
    "X_valid_3d=stack_to_multi(X_valid)\n",
    "X_test_3d=stack_to_multi(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65317, 180, 17)\n",
      "(16330, 180, 17)\n",
      "(20412, 180, 17)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_3d.shape)\n",
    "print(X_valid_3d.shape)\n",
    "print(X_test_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65317, 1)\n",
      "(16330, 1)\n",
      "(20412, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D 스케일링, 타겟 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=preprocessing.MinMaxScaler()\n",
    "#scaler_y=preprocessing.MinMaxScaler()\n",
    "def fit_3d(x_train,x_val,x_test):\n",
    "    x_train_sample = x_train.shape[0] #샘플 개수\n",
    "    x_val_sample=x_val.shape[0]\n",
    "    x_test_sample=x_test.shape[0]\n",
    "    \n",
    "    x_timestep = x_train.shape[1] # timestep\n",
    "    x_feature = x_train.shape[2]# feature 차원 \n",
    "    scaler=MinMaxScaler()\n",
    "    for ss in range(x_timestep):\n",
    "        scaler.partial_fit(x_train[:, ss, :]) # 순회피팅\n",
    "\n",
    "    results1,results2,results3=([],[],[])\n",
    "    for ss in range(x_timestep):\n",
    "        results1.append(scaler.transform(x_train[:, ss, :]).reshape(x_train_sample, 1, x_feature))\n",
    "        results2.append(scaler.transform(x_val[:,ss,:]).reshape(x_val_sample,1,x_feature))\n",
    "        results3.append(scaler.transform(x_test[:,ss,:]).reshape(x_test_sample,1,x_feature))\n",
    "    df_train_scaled = np.concatenate(results1, axis=1) #합치기.\n",
    "    df_val_scaled=np.concatenate(results2,axis=1)\n",
    "    df_test_scaled=np.concatenate(results3,axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df_train_scaled,df_val_scaled,df_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled,X_valid_scaled,X_test_scaled=fit_3d(X_train_3d, X_valid_3d, X_test_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> target shape 변경 ( 샘플 x 타입스텝 x 예측일수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subdiff=X_train['sub_diff']\n",
    "X_valid_subdiff=X_valid['sub_diff']\n",
    "X_test_subdiff=X_test['sub_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "      <th>sub_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24830</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11981</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31747</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49094</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48507</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82157</th>\n",
       "      <td>50.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73539</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75468</th>\n",
       "      <td>110.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41133</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65317 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sub_diff  sub_diff  sub_diff  sub_diff  sub_diff  sub_diff  sub_diff  \\\n",
       "24830       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "24979     100.0     100.0     399.0     100.0     101.0     100.0     200.0   \n",
       "11981      50.0      50.0       0.0       0.0       0.0     100.0       0.0   \n",
       "31747       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "49094       3.0       3.0       4.0       4.0       5.0      10.0       6.0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "48507      40.0       0.0      10.0      15.0      15.0      30.0      20.0   \n",
       "82157      50.0      65.0      65.0      60.0     110.0      25.0      25.0   \n",
       "73539     100.0       0.0       0.0       0.0       0.0       0.0      50.0   \n",
       "75468     110.0      50.0      40.0      40.0      20.0      60.0      50.0   \n",
       "41133       0.0       0.0       0.0      50.0      50.0       0.0       0.0   \n",
       "\n",
       "       sub_diff  sub_diff  sub_diff  ...  sub_diff  sub_diff  sub_diff  \\\n",
       "24830       0.0       0.0       0.0  ...       0.0       0.0    -100.0   \n",
       "24979     100.0     100.0     150.0  ...     200.0     100.0      99.0   \n",
       "11981       0.0       0.0     100.0  ...       0.0       0.0       0.0   \n",
       "31747       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "49094       6.0       6.0       6.0  ...      10.0      10.0      20.0   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "48507      70.0      10.0       0.0  ...      10.0     -20.0     -20.0   \n",
       "82157      40.0      40.0      90.0  ...     100.0       0.0     100.0   \n",
       "73539      50.0       0.0       0.0  ...       0.0      50.0      50.0   \n",
       "75468      70.0      50.0      20.0  ...       0.0     100.0     200.0   \n",
       "41133     100.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "\n",
       "       sub_diff  sub_diff  sub_diff  sub_diff  sub_diff  sub_diff  sub_diff  \n",
       "24830    -100.0       0.0    -100.0       0.0    -100.0       0.0    -100.0  \n",
       "24979     201.0     100.0     100.0     200.0     100.0     200.0     100.0  \n",
       "11981       0.0     100.0       0.0       0.0       0.0       0.0       0.0  \n",
       "31747     100.0       0.0     100.0       0.0       0.0       0.0       0.0  \n",
       "49094       5.0       5.0       0.0      10.0       0.0      10.0       5.0  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "48507      30.0      40.0      -5.0      -5.0      20.0     -20.0     -30.0  \n",
       "82157     100.0     200.0       0.0       0.0      99.0     101.0       0.0  \n",
       "73539       0.0     100.0       0.0       0.0     100.0       0.0     100.0  \n",
       "75468     100.0     300.0       0.0       0.0     100.0       0.0     100.0  \n",
       "41133       0.0       0.0       0.0       0.0      50.0      50.0       0.0  \n",
       "\n",
       "[65317 rows x 180 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_subdiff[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (샘플개수 , (180+30)의 TARGET\n",
    "temp1=pd.concat([X_train_subdiff,y_train],axis=1)\n",
    "temp2=pd.concat([X_valid_subdiff,y_valid],axis=1)\n",
    "temp3=pd.concat([X_test_subdiff,y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (샘플, timestep, targetsize)\n",
    "y_train_3d=np.empty((X_train_subdiff.shape[0],X_train_subdiff.shape[1],1)) # 30 : targetsize\n",
    "y_valid_3d=np.empty((X_valid_subdiff.shape[0],X_valid_subdiff.shape[1],1))\n",
    "y_test_3d=np.empty((X_test_subdiff.shape[0],X_test_subdiff.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(X_train_subdiff.shape[1]): # 180 Timestep\n",
    "    y_train_3d[:,t]=temp1.iloc[:,t:t+1]\n",
    "    y_valid_3d[:,t]=temp2.iloc[:,t:t+1]\n",
    "    y_test_3d[:,t]=temp3.iloc[:,t:t+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65317, 180, 1)\n",
      "(16330, 180, 1)\n",
      "(20412, 180, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_3d.shape)\n",
    "print(y_valid_3d.shape)\n",
    "print(y_test_3d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> y scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_temp=y_train_3d.reshape(-1,1)\n",
    "y_valid_temp=y_valid_3d.reshape(-1,1)\n",
    "y_test_temp=y_test_3d.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_y=MinMaxScaler()\n",
    "y_train_scaled=scaler_y.fit_transform(y_train_temp)\n",
    "y_val_scaled=scaler_y.transform(y_valid_temp)\n",
    "y_test_scaled=scaler_y.transform(y_test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scaled=y_train_scaled.reshape(y_train_3d.shape[0],y_train_3d.shape[1],y_train_3d.shape[2])\n",
    "y_valid_scaled=y_val_scaled.reshape(y_valid_3d.shape[0],y_valid_3d.shape[1],y_valid_3d.shape[2])\n",
    "y_test_scaled=y_test_scaled.reshape(y_test_3d.shape[0],y_test_3d.shape[1],y_test_3d.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65317, 180, 1)\n",
      "(16330, 180, 1)\n",
      "(20412, 180, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_scaled.shape)\n",
    "print(y_valid_scaled.shape)\n",
    "print(y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 마지막 Timestep의 loss만 중요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_absolute_error(Y_true[:, -1], Y_pred[:, -1]) #### <<- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='ConvGRU(180_1_1).h5'\n",
    "callback_list1 = [tf.keras.callbacks.ModelCheckpoint(filepath='Checkpoint/{}'.format(filename),\n",
    "                                                    monitor='val_last_time_step_mse',\n",
    "                                                    verbose=1,\n",
    "                                                    save_best_only=True,\n",
    "                                                    mode='min'),\n",
    "                 tf.keras.callbacks.EarlyStopping(monitor='val_last_time_step_mse',\n",
    "                                                  patience=15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, None, 180)         15480     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, None, 180)         195480    \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, None, 180)         195480    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 1)           181       \n",
      "=================================================================\n",
      "Total params: 406,621\n",
      "Trainable params: 406,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=180, kernel_size=5, strides=3, padding=\"valid\",\n",
    "                        input_shape=[None, 17]),\n",
    "    #-------뭐라도 해보기 ----- OK, !! \n",
    "    #keras.layers.MaxPooling1D(pool_size=1, strides=None),\n",
    "    keras.layers.GRU(180, return_sequences=True),\n",
    "    keras.layers.GRU(180, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
    "    ,\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[last_time_step_mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1563/2042 [=====================>........] - ETA: 34s - loss: 1.2537e-04 - last_time_step_mse: 1.1012e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-5ece1f90204d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(X_train_scaled, y_train_scaled[:, 4::3], epochs=80,\n\u001b[0;32m----> 2\u001b[0;31m                     validation_data=(X_valid_scaled,y_valid_scaled[:, 4::3]),callbacks=callback_list1)\n\u001b[0m",
      "\u001b[0;32m~/wheresmydog/Cancer/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/wheresmydog/Cancer/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/wheresmydog/Cancer/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/wheresmydog/Cancer/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/wheresmydog/Cancer/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/wheresmydog/Cancer/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/wheresmydog/Cancer/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/wheresmydog/Cancer/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/wheresmydog/Cancer/venv/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train_scaled[:, 4::3], epochs=80,\n",
    "                    validation_data=(X_valid_scaled,y_valid_scaled[:, 4::3]),callbacks=callback_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_Full.history['last_time_step_mse'], label='train_loss')\n",
    "plt.plot(history_Full.history['val_last_time_step_mse'], label='val_loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='Wavenet(180_1_1)(plusepochs).h5'\n",
    "callback_list2 = [tf.keras.callbacks.ModelCheckpoint(filepath='Checkpoint/{}'.format(filename),\n",
    "                                                    monitor='val_last_time_step_mse',\n",
    "                                                    verbose=1,\n",
    "                                                    save_best_only=True,\n",
    "                                                    mode='min'),\n",
    "                 tf.keras.callbacks.EarlyStopping(monitor='val_last_time_step_mse',\n",
    "                                                  patience=15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2041/2042 [============================>.] - ETA: 0s - loss: 1.5716e-04 - last_time_step_mse: 1.5078e-04\n",
      "Epoch 00001: val_last_time_step_mse improved from inf to 0.00007, saving model to Checkpoint/Wavenet(180_1_1)(plusepochs).h5\n",
      "2042/2042 [==============================] - 59s 29ms/step - loss: 1.5715e-04 - last_time_step_mse: 1.5077e-04 - val_loss: 8.3095e-05 - val_last_time_step_mse: 7.1247e-05\n",
      "Epoch 2/40\n",
      "2040/2042 [============================>.] - ETA: 0s - loss: 1.6123e-04 - last_time_step_mse: 1.5540e-04\n",
      "Epoch 00002: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 56s 28ms/step - loss: 1.6119e-04 - last_time_step_mse: 1.5535e-04 - val_loss: 1.2714e-04 - val_last_time_step_mse: 1.1232e-04\n",
      "Epoch 3/40\n",
      "2042/2042 [==============================] - ETA: 0s - loss: 1.5892e-04 - last_time_step_mse: 1.5218e-04\n",
      "Epoch 00003: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 57s 28ms/step - loss: 1.5892e-04 - last_time_step_mse: 1.5218e-04 - val_loss: 9.7875e-05 - val_last_time_step_mse: 9.5891e-05\n",
      "Epoch 4/40\n",
      "2042/2042 [==============================] - ETA: 0s - loss: 1.5266e-04 - last_time_step_mse: 1.4748e-04\n",
      "Epoch 00004: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 61s 30ms/step - loss: 1.5266e-04 - last_time_step_mse: 1.4748e-04 - val_loss: 2.8329e-04 - val_last_time_step_mse: 2.9986e-04\n",
      "Epoch 5/40\n",
      "2040/2042 [============================>.] - ETA: 0s - loss: 1.5718e-04 - last_time_step_mse: 1.5218e-04\n",
      "Epoch 00005: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 58s 28ms/step - loss: 1.5722e-04 - last_time_step_mse: 1.5219e-04 - val_loss: 1.0596e-04 - val_last_time_step_mse: 9.7904e-05\n",
      "Epoch 6/40\n",
      "2042/2042 [==============================] - ETA: 0s - loss: 1.4168e-04 - last_time_step_mse: 1.3618e-04\n",
      "Epoch 00006: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 58s 29ms/step - loss: 1.4168e-04 - last_time_step_mse: 1.3618e-04 - val_loss: 4.1010e-04 - val_last_time_step_mse: 4.1137e-04\n",
      "Epoch 7/40\n",
      "2040/2042 [============================>.] - ETA: 0s - loss: 1.6012e-04 - last_time_step_mse: 1.5458e-04\n",
      "Epoch 00007: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 59s 29ms/step - loss: 1.6018e-04 - last_time_step_mse: 1.5464e-04 - val_loss: 1.2962e-04 - val_last_time_step_mse: 1.1368e-04\n",
      "Epoch 8/40\n",
      "2040/2042 [============================>.] - ETA: 0s - loss: 1.4974e-04 - last_time_step_mse: 1.4437e-04\n",
      "Epoch 00008: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 60s 30ms/step - loss: 1.4975e-04 - last_time_step_mse: 1.4439e-04 - val_loss: 2.5415e-04 - val_last_time_step_mse: 2.5489e-04\n",
      "Epoch 9/40\n",
      "2040/2042 [============================>.] - ETA: 0s - loss: 1.4423e-04 - last_time_step_mse: 1.3795e-04\n",
      "Epoch 00009: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 59s 29ms/step - loss: 1.4427e-04 - last_time_step_mse: 1.3801e-04 - val_loss: 1.8238e-04 - val_last_time_step_mse: 1.8984e-04\n",
      "Epoch 10/40\n",
      "2040/2042 [============================>.] - ETA: 0s - loss: 1.4883e-04 - last_time_step_mse: 1.4279e-04\n",
      "Epoch 00010: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 59s 29ms/step - loss: 1.4882e-04 - last_time_step_mse: 1.4279e-04 - val_loss: 1.6362e-04 - val_last_time_step_mse: 1.5009e-04\n",
      "Epoch 11/40\n",
      "2039/2042 [============================>.] - ETA: 0s - loss: 1.5349e-04 - last_time_step_mse: 1.4816e-04\n",
      "Epoch 00011: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 59s 29ms/step - loss: 1.5343e-04 - last_time_step_mse: 1.4809e-04 - val_loss: 2.0765e-04 - val_last_time_step_mse: 2.1065e-04\n",
      "Epoch 12/40\n",
      "2040/2042 [============================>.] - ETA: 0s - loss: 1.5753e-04 - last_time_step_mse: 1.5255e-04\n",
      "Epoch 00012: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 59s 29ms/step - loss: 1.5751e-04 - last_time_step_mse: 1.5251e-04 - val_loss: 1.1376e-04 - val_last_time_step_mse: 8.9751e-05\n",
      "Epoch 13/40\n",
      "2041/2042 [============================>.] - ETA: 0s - loss: 1.4361e-04 - last_time_step_mse: 1.3797e-04\n",
      "Epoch 00013: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 56s 28ms/step - loss: 1.4361e-04 - last_time_step_mse: 1.3797e-04 - val_loss: 1.5257e-04 - val_last_time_step_mse: 1.2024e-04\n",
      "Epoch 14/40\n",
      "2041/2042 [============================>.] - ETA: 0s - loss: 1.4708e-04 - last_time_step_mse: 1.4187e-04\n",
      "Epoch 00014: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 55s 27ms/step - loss: 1.4707e-04 - last_time_step_mse: 1.4187e-04 - val_loss: 9.2070e-05 - val_last_time_step_mse: 7.6309e-05\n",
      "Epoch 15/40\n",
      "2039/2042 [============================>.] - ETA: 0s - loss: 1.4024e-04 - last_time_step_mse: 1.3566e-04\n",
      "Epoch 00015: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 59s 29ms/step - loss: 1.4027e-04 - last_time_step_mse: 1.3566e-04 - val_loss: 1.2267e-04 - val_last_time_step_mse: 1.2966e-04\n",
      "Epoch 16/40\n",
      "2040/2042 [============================>.] - ETA: 0s - loss: 1.4852e-04 - last_time_step_mse: 1.4363e-04\n",
      "Epoch 00016: val_last_time_step_mse did not improve from 0.00007\n",
      "2042/2042 [==============================] - 58s 28ms/step - loss: 1.4859e-04 - last_time_step_mse: 1.4369e-04 - val_loss: 2.0092e-04 - val_last_time_step_mse: 1.9809e-04\n"
     ]
    }
   ],
   "source": [
    "history_Full2= model_Full.fit(X_train_scaled, y_train_scaled, epochs=40,\n",
    "                    validation_data=(X_valid_scaled,y_valid_scaled),callbacks=callback_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_Full2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-60918f5df902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_Full2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_time_step_mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_Full2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_last_time_step_mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_Full2' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history_.history['last_time_step_mse'], label='train_loss')\n",
    "plt.plot(history_Full2.history['val_last_time_step_mse'], label='val_loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 첫번째 모델로 하는게 나음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cancer",
   "language": "python",
   "name": "cancer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
